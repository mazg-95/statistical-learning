{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fa1ab8-3ab6-4b5f-9648-c98c6ca2c418",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95177cf8-7a6b-4aea-ab6a-c48310769c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf811a-c1a2-4448-a74e-4c7764966b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b55f8-5fac-4314-8ed8-7f3cf8b1d2f3",
   "metadata": {},
   "source": [
    "SVM viene de Support Vector Machines, es un algoritmo diferente a la regression logistica dado, que aunque se basa en las mismas ideas.\n",
    "Agrega una seccion de confianza que no tiene la regresion logistica. Y eso muchas veces lo hace mas robusto y capaz de generalizar mejor el aprendizaje.\n",
    "\n",
    "### SVM \n",
    "\n",
    "Es un algoritmo de aprendizaje supervisado creado por Vladimir Vapnik junto a otros colegas en el AT&T Bell Laboratories. Y es un algoritmo que es ampliamente popular en aplicaciones biologicas.\n",
    "Es usado para clasificacion, regresion o detectar outliers. \n",
    "\n",
    "\n",
    "#### Ventajas\n",
    "- Efectivo en espcaios de muchas dimensiones\n",
    "- Se mantiene efectivo en casos donde el numero de dimensiones es mayor al numero de muestras.\n",
    "- Usa un subset de puntos de entrenamiento en la funcion de decision que utiliza de soporte. (Support Vectors). \n",
    "- Versatil, ya que se puede customizar el kernel para la funcion de decision.\n",
    "\n",
    "\n",
    "#### Desventajas\n",
    "- Es posible el sobreajuste si el numero de caracteristicas es mucho mayor que el numero de muestras. Dependera de la decision de los hyperparametros para evitarlo.\n",
    "- No calcula estimaciones de probabildad directamente, sino calcula un 5 Fold CV costoso.\n",
    "\n",
    "\n",
    "Ejemplo de lineas de decision en regresion logistica:\n",
    "<figure>\n",
    "<img id=\"img1\" src=\"https://miro.medium.com/max/600/0*9jEWNXTAao7phK-5.png\">\n",
    "</figure>\n",
    "\n",
    "Ejemplo de una linea de decision optima (SVM):\n",
    "<figure>\n",
    "<img id=\"img1\" src=\"https://miro.medium.com/max/600/0*0o8xIA4k3gXUDCFU.png\">\n",
    "</figure>\n",
    "\n",
    "\n",
    "Los modelos SVM se consideran algoritmos de aprendizaje robustos dado ha estas lineas de soporte que ayudan a encontrar una barrera de decision optima. El plano de separacion entre clases que genera, le otorga la robustez que le caracteriza.\n",
    "\n",
    "SVM  se basa en que la predicion ya no tomara valores de 0 o 1. Sino cambia estos valores por -1 y 1. Ademas la funcion de costo tambien cambia dado en parte a este cambio. Pero la hipotesis por lo tanto tomara la forma siguiente: \n",
    "$$h_{w,b}(x) = g(w^{T} x + b)$$\n",
    "\n",
    "Notese que sigue siendo una hipotesis similar a la regresion logisitca. La diferencia ahora es que se ha aumentado el margen para separar las clases. Lo que se busca ahora es que *g(z) = 1* cuando *z* que es igual a  $$w^{T} x + b)$$ sea mucho mayor a 1. La frontera de decision ya no es solamente una linea. Por lo tanto *g(z) = 1* cuando *z* sea negativo. \n",
    "\n",
    "Nuestra funcion de costo entoces buscara generar mayor penalizacion para los casos en los que si $$y = 1$$ y $$w^{T} x + b) < 0$$ y cuando  $$y = 0$$ pero $$w^{T} x + b) > 0$$\n",
    "\n",
    "### Bibliografia\n",
    "[Scikit Learn SVM](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
